{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a507dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loaded 100 examples from test_hospital_1.jsonl\n",
      "Connecting to database: spider_data/database/hospital_1/hospital_1.sqlite\n",
      "Loading model: juierror/flan-t5-text2sql-with-schema-v2 on mps...\n",
      "\n",
      "Evaluating on 100 examples...\n",
      "--------------------------------------------------\n",
      "[10/100] EM=0.000 EX=0.200 Valid=0.200\n",
      "[20/100] EM=0.150 EX=0.400 Valid=0.400\n",
      "[30/100] EM=0.167 EX=0.367 Valid=0.433\n",
      "[40/100] EM=0.150 EX=0.300 Valid=0.400\n",
      "[50/100] EM=0.180 EX=0.300 Valid=0.400\n",
      "[60/100] EM=0.167 EX=0.350 Valid=0.467\n",
      "[70/100] EM=0.157 EX=0.314 Valid=0.457\n",
      "[80/100] EM=0.163 EX=0.300 Valid=0.425\n",
      "[90/100] EM=0.144 EX=0.267 Valid=0.378\n",
      "[100/100] EM=0.150 EX=0.280 Valid=0.380\n",
      "\n",
      "==================================================\n",
      "=== SUMMARY ===\n",
      "Model: juierror/flan-t5-text2sql-with-schema-v2\n",
      "Examples: 100\n",
      "Exact Match (EM):        15.000%\n",
      "Execution Accuracy (EX): 28.000%\n",
      "Valid-SQL rate:          38.000%\n",
      "Median gen latency:      2778.4 ms\n",
      "Saved: results_hospital_1_flan.csv\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# eval_flan_hospital1.py\n",
    "import json, time, csv, sqlite3\n",
    "from pathlib import Path\n",
    "import sqlglot\n",
    "from sqlglot import parse_one\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "EVAL_JSONL = Path(\"test_hospital_1.jsonl\")  # Use the clean test file you just created\n",
    "RESULTS_CSV = Path(\"results_hospital_1_flan.csv\")\n",
    "MODEL_NAME = \"juierror/flan-t5-text2sql-with-schema-v2\"\n",
    "\n",
    "GEN_KW = dict(\n",
    "    max_new_tokens=256,\n",
    "    num_beams=4,\n",
    "    do_sample=False,\n",
    "    no_repeat_ngram_size=3,\n",
    ")\n",
    "\n",
    "# Better device detection for MacBook\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"  # Apple Silicon GPU\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "INSTR = (\n",
    "    \"Question: {question}\\n\\n\"\n",
    "    \"{schema}\\n\\n\"\n",
    "    \"SQL:\"\n",
    ")\n",
    "\n",
    "def load_eval(jsonl_path):\n",
    "    rows = []\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "def canonical_sql(sql_text):\n",
    "    \"\"\"Normalize SQL to canonical form for EM comparison.\"\"\"\n",
    "    if not sql_text:\n",
    "        return None\n",
    "    try:\n",
    "        ast = parse_one(sql_text, read=\"sqlite\")\n",
    "        return ast.sql(dialect=\"sqlite\", pretty=False)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def extract_sql(text):\n",
    "    \"\"\"Extract SQL from model output.\"\"\"\n",
    "    t = text.strip()\n",
    "    \n",
    "    # Remove code fences if present\n",
    "    if \"```\" in t:\n",
    "        parts = t.split(\"```\")\n",
    "        for seg in parts:\n",
    "            seg_l = seg.lower()\n",
    "            if \"select\" in seg_l or \"with \" in seg_l:\n",
    "                t = seg.strip()\n",
    "                # Remove \"sql\" language marker if present\n",
    "                if t.lower().startswith(\"sql\"):\n",
    "                    t = t[3:].strip()\n",
    "                break\n",
    "    \n",
    "    # Drop leading labels\n",
    "    for head in [\"sql:\", \"answer:\", \"query:\", \"sqlite:\"]:\n",
    "        if t.lower().startswith(head):\n",
    "            t = t[len(head):].strip()\n",
    "    \n",
    "    # Take up to first semicolon if present\n",
    "    if \";\" in t:\n",
    "        t = t.split(\";\", 1)[0] + \";\"\n",
    "    \n",
    "    return t.strip()\n",
    "\n",
    "def try_execute(conn, sql_text):\n",
    "    \"\"\"Execute SQL and return normalized result set.\"\"\"\n",
    "    try:\n",
    "        cur = conn.execute(sql_text)\n",
    "        rows = cur.fetchall()\n",
    "        \n",
    "        # Normalize rows\n",
    "        normalized = []\n",
    "        for row in rows:\n",
    "            norm_row = []\n",
    "            for val in row:\n",
    "                if isinstance(val, float):\n",
    "                    norm_row.append(round(val, 6))\n",
    "                else:\n",
    "                    norm_row.append(val)\n",
    "            normalized.append(tuple(norm_row))\n",
    "        \n",
    "        return set(normalized), None\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "def main():\n",
    "    # Check file exists\n",
    "    if not EVAL_JSONL.exists():\n",
    "        print(f\"ERROR: {EVAL_JSONL} not found!\")\n",
    "        print(f\"Make sure you have the test_hospital_1.jsonl file in the current directory.\")\n",
    "        return\n",
    "    \n",
    "    data = load_eval(EVAL_JSONL)\n",
    "    print(f\"Loaded {len(data)} examples from {EVAL_JSONL}\")\n",
    "    \n",
    "    # Get SQLite path from first example\n",
    "    sqlite_path = Path(data[0][\"sqlite_path\"])\n",
    "    if not sqlite_path.exists():\n",
    "        print(f\"ERROR: SQLite database not found: {sqlite_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Connecting to database: {sqlite_path}\")\n",
    "    conn = sqlite3.connect(str(sqlite_path))\n",
    "    conn.execute(\"PRAGMA foreign_keys=ON\")\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"Loading model: {MODEL_NAME} on {DEVICE}...\")\n",
    "    tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    # Move to device ONLY if not CPU\n",
    "    if DEVICE != \"cpu\":\n",
    "        model.to(DEVICE)\n",
    "    \n",
    "    model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    results = []\n",
    "    n = len(data)\n",
    "    valid_cnt = em_cnt = ex_cnt = 0\n",
    "    latencies = []\n",
    "    \n",
    "    print(f\"\\nEvaluating on {n} examples...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, ex in enumerate(data, 1):\n",
    "        question = ex[\"question\"]\n",
    "        gold_sql = ex[\"gold_query\"]\n",
    "        schema_str = ex[\"schema_serialized\"]\n",
    "        \n",
    "        # Build prompt\n",
    "        prompt = INSTR.format(question=question, schema=schema_str)\n",
    "        \n",
    "        # Generate\n",
    "        t0 = time.time()\n",
    "        inp = tok(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        \n",
    "        # Move input to device if needed\n",
    "        if DEVICE != \"cpu\":\n",
    "            inp = {k: v.to(DEVICE) for k, v in inp.items()}\n",
    "        \n",
    "        out_ids = model.generate(**inp, **GEN_KW)\n",
    "        gen_ms = (time.time() - t0) * 1000.0\n",
    "        \n",
    "        pred_text = tok.decode(out_ids[0], skip_special_tokens=True)\n",
    "        pred_sql_raw = extract_sql(pred_text)\n",
    "        \n",
    "        # Normalize for EM\n",
    "        pred_sql_norm = canonical_sql(pred_sql_raw)\n",
    "        gold_sql_norm = canonical_sql(gold_sql)\n",
    "        \n",
    "        em = int(\n",
    "            pred_sql_norm is not None and \n",
    "            gold_sql_norm is not None and \n",
    "            pred_sql_norm == gold_sql_norm\n",
    "        )\n",
    "        \n",
    "        # Execution accuracy\n",
    "        valid = 0\n",
    "        ex_ok = 0\n",
    "        exec_err = None\n",
    "        \n",
    "        if pred_sql_norm is not None:\n",
    "            pred_rows, exec_err = try_execute(conn, pred_sql_norm)\n",
    "            if pred_rows is not None:\n",
    "                valid = 1\n",
    "                gold_rows, gold_err = try_execute(conn, gold_sql_norm or gold_sql)\n",
    "                if gold_rows is not None:\n",
    "                    ex_ok = int(pred_rows == gold_rows)\n",
    "                else:\n",
    "                    exec_err = f\"Gold failed: {gold_err}\"\n",
    "        else:\n",
    "            exec_err = \"ParseError\"\n",
    "        \n",
    "        # Accumulate metrics\n",
    "        valid_cnt += valid\n",
    "        em_cnt += em\n",
    "        ex_cnt += ex_ok\n",
    "        latencies.append(gen_ms)\n",
    "        \n",
    "        results.append({\n",
    "            \"id\": ex[\"id\"],\n",
    "            \"question\": question,\n",
    "            \"gold_sql\": gold_sql,\n",
    "            \"pred_sql_raw\": pred_sql_raw,\n",
    "            \"pred_sql_norm\": pred_sql_norm or \"\",\n",
    "            \"em\": em,\n",
    "            \"ex\": ex_ok,\n",
    "            \"valid_sql\": valid,\n",
    "            \"latency_ms\": round(gen_ms, 2),\n",
    "            \"error\": exec_err or \"\"\n",
    "        })\n",
    "        \n",
    "        # Progress updates\n",
    "        if i % 10 == 0 or i == n:\n",
    "            print(f\"[{i}/{n}] EM={em_cnt/i:.3f} EX={ex_cnt/i:.3f} Valid={valid_cnt/i:.3f}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open(RESULTS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=list(results[0].keys()))\n",
    "        w.writeheader()\n",
    "        w.writerows(results)\n",
    "    \n",
    "    # Summary\n",
    "    em_rate = em_cnt / n\n",
    "    ex_rate = ex_cnt / n\n",
    "    valid_rate = valid_cnt / n\n",
    "    med_latency = sorted(latencies)[len(latencies)//2]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"=== SUMMARY ===\")\n",
    "    print(f\"Model: {MODEL_NAME}\")\n",
    "    print(f\"Examples: {n}\")\n",
    "    print(f\"Exact Match (EM):        {em_rate:.3%}\")\n",
    "    print(f\"Execution Accuracy (EX): {ex_rate:.3%}\")\n",
    "    print(f\"Valid-SQL rate:          {valid_rate:.3%}\")\n",
    "    print(f\"Median gen latency:      {med_latency:.1f} ms\")\n",
    "    print(f\"Saved: {RESULTS_CSV}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd5d2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
